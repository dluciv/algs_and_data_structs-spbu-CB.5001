<span id="slides-title" hidden>Рандомизированные алгоритмы</span>

# Что мы обсуждаем

* Рандомизированные алгоритмы
* Неточные и субоптимальные решения
* Рандомизация
* Примеры конкретных алгоритмов и моделей
* Реализация и применение алгоритмов и моделей

= = = = = =

# Рандомизированные алгоритмы

- - - - - -

## Понятие рандомизированного алгоритма

**Рандомизированный алгоритм** — алгоритм, в котором выполнение одного или несколько шагов основано на слу-чайном правиле, т. е. среди многи хдетерминированны хправил од-но выбирается случайно в соответствии с вероятностью

Рандомизированный алгоритм называется **вероятностно-успешным** с вероятностью $p$, если вероятность егоправильного результата не меньше $p$

**Литература**

* Граничин О.Н. [Рандомизированные алгоритмы в задачах обработки данных и принятия решений](https://www.math.spbu.ru/user/gran/papers/10580575.pdf) / О.Н. Граничин // Системное программирование 6(1) 2011 — СПб.: Издательство С.-Петербургского университета - С. 141-162
* [Журнал «Стохастическая оптимизация в информатике»](https://www.elibrary.ru/title_about.asp?id=28931)
* Любой учебник по теории вероятностей, рекомендованный среди литературы к соответствующему курсу

- - - - - -

## Примеры классов рандомизированных алгоритмов

* На основе метода Монте-карло *
* На основе «метода» Лас-Вегаса
* На основе локального рандомизированного (не градиентного) спуска
  * Генетические — подбор параметров, задачи комивояжёра т т.д. *
* Алгоритмы аппроксимации функций
  * Compressive sensing 
* Построение маршрутов *

@pause@

\* Радикальное снижение вычислительной сложности за счёт допустимости *субоптимальных решений*

@pause@

Для [некоторых алгоритмически неразрешимых задач](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8_%D0%BD%D0%B5%D1%80%D0%B0%D0%B7%D1%80%D0%B5%D1%88%D0%B8%D0%BC%D0%B0%D1%8F_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0#%D0%94%D1%80%D1%83%D0%B3%D0%B8%D0%B5_%D0%BF%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D1%8B) существуют алгоритмы поиска неточных и неполных решений

= = = = = =

# Метод Монте-карло

- - - - - -

## Область применения метода Монте-Карло

Приближённое вычисление интегральных величин, требующих сканирования областей определения. Например (буквально):

$$\int_{x \in \Omega} f(x)dx$$

можно численно вычислить методами прямоугольников или трапеций...

@pause@

... но только когда мощность $\Omega$ сравнительно невелика.

- - - - - -

## Вычисление определённых интегралов методом Монте-Карло

Для $\Omega = \prod_{i=1}^N [x_{i,1}, x_{i,2}]$ и $f: D(f) = \Omega \rightarrow V(f) = [\min_\Omega f, \max_\Omega f]$ возьмём N равномерно распределённых точек $(x_1, \ldots, x_n, y) \in D(f) \times V(f)$; при этом $\exists K \in 0:N:$ для $K$ из этих точек $f(x_1, \ldots, x_n) \ge y$. Тогда

$$\int_{x\in\Omega} f(x)dx \approx \operatorname{MC}_f(\Omega) = |D(f) \times V(f)| \frac{K}{N}$$

- - - - - -

## Кто придумал и развивал метод Монте-Карло

* Джон фон Нейман при работе в Манхеттенском проекте в 1940-х
* 1950-е ... уже много кто и много где
* Много наших коллег в частности под руководством проф. С.М. Ермакова

- - - - - -

# ...

<div style="text-align: center;">

![](img5/05.randomized/monte-carlo_knight.jpg) <!--.element: style="width: 85%;" -->

</div>

- - - - - -

## Пример задачи для метода Монте-Карло

Объём $N$-мерного шара:

$$V_n(R) = \frac{\pi^{n/2}}{\Gamma(\frac{n}{2} + 1)}R^n$$

@pause@

Допустим мы не умеем вычислять $\Gamma$ и не знаем, что в отдельности для чётно- и нечётномерных пространств можно обойтись без неё, зная, что $\Gamma(z+1)=z!$ для $z \in \mathbb{Z}^+$.

- - - - - -

# Немного из теории вероятностей (1)

**Случайная величина** ...

@pause@

**Функция распределения** случайной величины

$$\operatorname{F}_\xi(x) = \operatorname{P}(\xi \le x)$$

@pause@

**Плотность распределения** случайной величины

* Для непрерывных $\operatorname{p}\_\xi(x): \int_{-\infty}^x \operatorname{p}\_\xi(x)dx = \operatorname{F}\_\xi(x) $
* Для дискретных --- аналогично, но сумма

@pause@

**Математическое ожидание**

$$\operatorname{E}(\xi) = \int_{-\infty}^{\infty} x d \operatorname{F}_\xi(x)$$

Для дискретных --- взвешенная сумма

@pause@

**Дисперсия** случайной величины

$$\operatorname{D}(\xi) = \operatorname{E}((\xi - \operatorname{E}\xi)^2)$$

- - - - - -

# Немного из теории вероятностей (2)

**Закон больших чисел** (в формулировке Чебышёва): если $\operatorname{F}\_{\xi\_1} = \ldots = \operatorname{F}\_{\xi\_n}$ и $\operatorname{E}\xi\_{1}^{2} < \infty$, то

$$\frac{1}{n}\sum_{i=1}^{n}\xi_i \rightarrow \operatorname{E}\xi_1$$

**Неравенство Чебышёва**

$$\operatorname{P}(|\xi-\operatorname{E}\xi|\ge\varepsilon) \le \frac{\operatorname{D}\xi}{\varepsilon^2}$$

@pause@

**Центральная пределльная теорема**

$\xi_1, \ldots \xi_n$ --- независимые одинаково распределённые случайные величины, такие что $\operatorname{E}\xi_1 = \mu, \operatorname{D}\xi_1 = \sigma^2$. Тогда

$$\frac{\sum_{i=1}^n {\xi_i} - n\mu}{\sigma\sqrt{n}} \rightarrow N(0, 1)$$

где $N(0, 1)$ --- *нормальное распределение*: $\operatorname{p}_{N(0, 1)}(x) = \frac{e^{-1/2 x^2}}{\sqrt{2\pi}}$

- - - - - -

# Точность метода Монте-Карло теоретически

$$\operatorname{P} ( \left| \frac{\operatorname{MC}\_f(\Omega)}{|D(f) \times V(f)|} -
  \frac{K}{N} \right| \ge \varepsilon )$$
  
  $$\le$$

 $$ 
  \frac{
    \operatorname{MC}\_f(\Omega)(|D(f) \times V(f)| - \operatorname{MC}\_f(\Omega))
  }{
    N \varepsilon^2 |D(f) \times V(f)|^2
  }
  $$

@pause@

Т.е. для оценки «относительной погрешности» (на самом деле нет) надо уже что-то посчитать, сразу сказать нельзя

- - - - - -

# Точность метода Монте-Карло практически

<div style="text-align: center;">

![Из Википедии](img5/05.randomized/Pi_30K.gif) <!--.element: style="width: 50%;" -->

</div>

- - - - - -

## Оптимизация

Различные способы, предписывающие использовать не равномерное распределение в $\Omega$ и учитывающие это распределение при вычислении окончательного результата.

@pause@

Напрмер, в форме построения: разбить $\Omega$ на параллелотопы $\Omega_j$. При этом, вероятно, уменьшится (по крайней мере не увеличится) $|V_{\Omega_j}(f)| \le |V_\Omega(f)|$, что снизит количество точек.

Фактически, это эвристический гибрид с методом прямоугольников.

= = = = = =

# Метод Лас-Вегаса

- - - - - -

## Суть метода

* Есть критерий проверки правильности решения
* Есть алгоритм, позволяющий генерировать все возможные решения

@pause@

* Повторять алгоритм, пока решение не удовлетворит критерию

- - - - - -

## Пример

Алгоритм сортировки **Bogosort** --- случайно переставлять элементы массива, пока массив не отсортируется.

Смешно?

@pause@

Пожалуй. Пока что. Ещё варианты и шутка про квантовый компьютер:

https://en.wikipedia.org/wiki/Bogosort#Related_algorithms

[Демонстрация Bogosort](https://www.youtube.com/watch?v=CSe0MWDLevA&lc=Ugyb4JdzuDtmYQhVM5p4AaABAg.8y_vesgJKXQ9C8jOrLC91j)

= = = = = =

# Compressive sensing

- - - - - -

## Теорема Котельникова

* Количество информации и количество данных
* «Комфортный шум»
* Повышение точности при помощи рандомизации

- - - - - -

## TODO

* Слайды из курса «Архитектура ВС»
* Рандомизация и повышение точности

= = = = = =

# Случайные деревья

- - - - - -

## Зачем это нужно?

Для поиска пути между двумя точками через невыпуклую фигуру. Например, в лабиринте.

Используется, в основном, в робототехнике и в других приложениях, связанных планированием движения.

- - - - - -

## Random Tree

1. Ставим корень
2. Берём случайный узел
3. Пускаем из него побег с новым узлом на конце
4. Повторяем с (2)

@pause@

Хорошо, но медленно

@pause@

Особенно для многомерных пространств. Аналогично случайным блужданиям по решёткам в теории вероятностей: когда измерения два, пересечения почти наверняка есть, когда больше --- очень часто нет.

- - - - - -

## RRT

<div style="text-align: center;">

![](img5/05.randomized/rrtkuffner_small.jpg) <!--.element: style="width: 50%;" -->

</div>

http://lavalle.pl/rrt/

[Демонстрашка](https://demonstrations.wolfram.com/RapidlyExploringRandomTreeRRTAndRRT/)

- - - - - -

# Пример оптимизации градиентного спуска

Пример — комбинирование с градиентным спуском. Если покрытие достаточно полное, переходить к градиентному спуску.

= = = = = =

# Вопросы и упражнения

## Вопросы

* ...

## Упражнения

* ...
