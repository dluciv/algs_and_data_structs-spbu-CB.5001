<span id="slides-title" hidden>Кэширование</span>

# Предмет лекции

- - - - - -

## Что мы обсуждаем

* Применение
  * Что кэшируется?
* Алгоритмы кэширования
  * Стратегии вытеснения (replacement, eviction)
  * Стратегии размещения
  * Спопобы поддержания когерентности
* Реализации кэшей
  * «Боевые»
  * «Исследовательские»

- - - - - -

# Что кэшируется?

- - - - - -

## Оперативные данные

* ЦП — ОЗУ
  * Современная RAM далеко не Random Access
  * Современные ЦП имеют несколько уровней кэша
* Математическая память
  * ОЗУ — «примерно» кэш математической памяти
    * в большинстве реализаций данные из виртуальной памяти в ОЗУ не копируются, а перемещаются

- - - - - -

## Долговременные данные

* Файловая система
  * Многие ОС достаточно агрессивно кэшируют файловую систему. Пример вывода `top`:
```
MiB Mem :  11899,7 total,    521,0 free,   3912,0 used,   7466,7 buff/cache
MiB Swap:  12288,0 total,  12286,7 free,      1,3 used.   7042,6 avail Mem
```

* Сетевые ресурсы
  * Распределённых кэши
  * Распределённые хэш-таблицы для кратковременного хранения

= = = = = =

# Общие принципы кэширования и свойства кэшей

- - - - - -

## Характеристики кэшей

Собственные свойства

* Очевидно — общий размер и размер записи
* Для аппаратных и распределённых
  * Ассоциативность
  * Способ обеспечения когерентности
* Стратегия размещения и вытеснания данных
* Максимальное время жизни записи (TTL)

В зависимости от свойств и порядка доступа

* Hit Ratio и Miss Ratio — доля кэш-попаданий и кэш-промахов (в сумме 1)
* Reuse Distance — количество обращений между обращениями к одной и той же записи в кэше

- - - - - -

## Принципы и алгоритмы вытеснения

В тех случаях, когда размер кэша фиксирован (например, кэш ЦП) или определяется однозначно (например, если под кэш ФС память выделяется  «в последнюю очередь»), кэш заполняется полностью, и задача — понять, что именно из кэша вытеснить.

- - - - - -

## Принцип вытеснения Белади

**Прицнип Ласло Белади** (он же **Принцип ясновидца**) — вытеснить запись, которая не понадобится дольше всего

Алгоритмизировать его невозможно

**Литература**

* Belady L. A. [A study of replacement algorithms for a virtual-storage computer](https://scholar.google.com/scholar?cluster=14870503344420591577) // IBM Systems journal. – 1966. – Т. 5. – №. 2. – С. 78-101.
* Belady L. A., Nelson R. A., Shedler G. S.  // Communications of the ACM. – 1969. – Т. 12. – №. 6. – С. 349-353. [An anomaly in space-time characteristics of certain programs running in a paging machine](https://scholar.google.com/scholar?cluster=3822730899899658691)

@pause@

* Ласло Белади, Тамаш Краус. [Сталин](https://www.ozon.ru/context/detail/id/4239152/) [пер. с венгерского] // Издательство политической литературы, 1990

= = = = = =

# Алгоритмы размещения и вытеснения

- - - - - -

## Тривиальные стратегии FIFO, LIFO (FILO)

* FIFO — кэш организцется, как очередь — вытесняется первый записанный
* LIFO — кэш организуется, как стек — вытесняется последний записанный

@pause@

А какой смысл в LIFO?..

@pause@

Без TTL смысла действительно нет

- - - - - -

## Стратегия вытеснения LRU

**Least Recently Used** — стратегия вытеснения, предписывающая вытеснить неиспользуемую дольше всех запись

* Вариант TLRU — с TTL

- - - - - -

## Аномалия Белади

**Спин-офф!**

@pause@

В целом обычно чем кэш больше, тем лучше.

@pause@

Но испортить можно всё. В данном случае дурное дело настолько нехитрое, что случается «в дикой природе».

**Аномалия Белади** — увеличение кэша при определённых порядке доступа к данным и стратегии вытеснения может ухудшить hit rate

[Пример для LRU](https://en.wikipedia.org/wiki/B%C3%A9l%C3%A1dy%27s_anomaly) (но м.б. и для других)

- - - - - -

## Алгоритмы Cache-Оblivious

**Спин-офф!**

@pause@

[**Cache-Оblivious**](https://en.wikipedia.org/wiki/Cache-oblivious_algorithm) — класс алгоритмов, которые эффективно используют кэш ЦП, не зная его размера (в т.ч. не приводят к проявлению аномалии Белади).

@pause@

Но неудачным сочетанием порядка доступа и стратегии вытеснения можно поломать всё, что угодно =)

- - - - - -

## Стратегия вытеснения MRU

**MRU** предписывает вытеснение записи, к которой обращались последней.

Согласно ряду исследований, показывает себя хорошо при множестве повторных проходов по массиву данных (например, JOIN без индеккса в реляционных БД)

**Литература**

* Hong-Tai Chou and David J. DeWitt. [An Evaluation of Buffer Management Strategies for Relational Database Systems](http://www.vldb.org/conf/1985/P127.PDF). VLDB, 1985.

- - - - - -

## Ассоциативность кэша

**Спин-офф!**

@pause@

<div style="text-align: center;">

![Картинка из Википедии](img5/01.caches/Cache%2Cassociative-fill-both.png)
 <!--.element: style="width: 70%;" -->

</div>

Показатель ассоциативности $\in \mathbb{N} + \\{\\infty\\}$.
[Примеры](http://www.informit.com/articles/article.aspx?p=482324&seqNum=3). Для размшыления: размер кэш-линии — параметр аналогичного характера.

- - - - - -

## Стратегия **размещения** и вытеснения Pseudo LRU (PLRU)

Пример для порядка обращения ABCDE — после каждого обращения к кэшу стрелки переключаются

<div style="text-align: center;">

![Картинка из Википедии](img5/01.caches/Plruexample.png)
 <!--.element: style="width: 70%;" -->

</div>

Использовалась, например, в i80486 и PowerPC, потому что при высокой ассоциативности LRU реализуется дороже.

- - - - - -

## Ещё вариянты LRU

### LFU (Least Frequently Used)

Использует не очерередь по времени, а счётчик обращений

### Стратегия **размещения** и вытеснения SLRU (Segmented LRU)

Разновидность двухуровневого LRU-кэша. Состоит из «вероятного» и «защищённого» разделов. Кэш-попадание в вероятном переносит запись в защищённый. Вытеснение из защищённого происходит в вероятный.

### Стратегия **размещения** и вытеснения LFRU

Как SLRU, но у «защищённого» раздела используется LRU, а у «вероятного» — LFU. Эффективен для кэширования контента в сетях ICN/CDN

**Литература**

* M. Bilal and S. Kang. [A Cache Management Scheme for Efficient Content Eviction and Replication in Cache Networks](https://ieeexplore.ieee.org/document/7857720) in IEEE Access, vol. 5, pp. 1692-1701, 2017

- - - - - -

## Стратегия **размещения** и вытеснения MQ (Multi queue)

Вариант SLRU и LFRU

* Организуется $m$ LRU-кэшей с TTL $Q_0,\\ldots,Q_{m-1}$
* В каждом следующем более долгоживущие записи
* По превышению TTL запись перемещается в менее долгоживущий кэш (или вообще вытесняется)
* По превышению количества обращений ($> 2^i$) запись перемещается $Q_i \rightarrow Q_{i+1}$

**Литература**

Yuanyuan Zhou, James Philbin, and Kai Li. [The Multi-Queue Replacement Algorithm for Second Level Buffer Caches](https://static.usenix.org/event/usenix01/zhou.html). USENIX, 2002.

- - - - - -

## Стратегия вытеснения RR (Random Replacement)

**RR** предписывает вытеснить случайного

@pause@

Несмотря на кажущееся радикальное безумие, довольно популярна. Используется во многих процессорах ARM

Оценка эффективности — стохастическая, как обычно у рандомизированных алгоритмов

**Литература**

* Zhou S. (2010) [An Efficient Simulation Algorithm for Cache of Random Replacement Policy](https://scholar.google.com/scholar?cluster=3131283367384024720). In: Ding C., Shao Z., Zheng R. (eds) Network and Parallel Computing. NPC 2010. Lecture Notes in Computer Science, vol 6289. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-642-15672-4_13

- - - - - -

## Стратегия **размещения** и вытеснения ARC (Adaptive replacement cache)

Организцется 4 кэша:

* $T_1$ — LRU
* $T_2$ — LFU
* $B_1$ — кого только что вытеснили из $T_1$, но пока не забыли
* $B_2$ — аналогично , но из $T_2$

$$L_1 = T_1 \\cup B_1, L_2 = T_2 \\cup B_2; \\; |T_1| + |T_2| = \\mathit{const}$$

* Новые элементы попадают в $T_1$. При последующих обращениях переносятся в $T_2$.
* С вытеснением всё интересние — можно [посмотреть](https://en.wikipedia.org/wiki/Adaptive_replacement_cache) в качестве упражнения

**Литература**

Megiddo N., Modha D. S. [ARC: A Self-Tuning, Low Overhead Replacement Cache](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.5210) // Fast. – 2003. – Т. 3. – №. 2003. – С. 115-130.

- - - - - -

## Дополнительно и системно

<div style="text-align: center;">

![Картинка из Википедии](img5/01.caches/ISPRAS_CAR_pdf.png)
 <!--.element: style="width: 90%;" -->

</div>

Сиващенко Дмитрий.
[Алгоритмы вытеснения страниц баз данных из буферов основной памяти](http://seminar.at.ispras.ru/2010/03/algoritmy-vytesneniya-stranic-baz-dannyx-iz-buferov-osnovnoj-pamyati-23-03-10/).
[Cеминар ИСП РАН](http://seminar.at.ispras.ru/wp-content/uploads/2010/03/CAR.pdf),
23.03.2010

= = = = = =

# Реализация: структуры данных

- - - - - -

## Структуры данных: Splay Tree

Неполное определение

**Splay Tree** — бинарное дерево поиска, в котором вставка происходит путём разделения дерева по добавляемому элементу, а при поиске найденный элемент вращениями поднимается в корень

В итоге недавно добавленные и «популярные» элементы оказываются близко к вершине, что ускоряет доступ к ним

Литература

* Sleator D. D., Tarjan R. E. [Self-adjusting binary search trees](https://scholar.google.com/scholar?cluster=11861151570680691608) // Journal of the ACM (JACM). – 1985. – Т. 32. – №. 3. – С. 652-686

@pause@

Специальных усилий по балансировке не предпринимается:

* при случайном доступе дерево в среднем «прилично» балансируется
* балансировка вообще не так важна, т.к. максимальное время поиска — не то, что оно пытается оптимизировать

- - - - - -

## Структуры данных: T-Tree (1)

Популярно для построения индексов целиком в ОЗУ, подходит для словарных структур данных вообще

* в противоположность B-дереву, котрое уместно на диске из-за сильного ветвления
* На самом деле не «T», а «t» за форму узла на иллюстрациях

**Описание**

**T-дерево** — бинарное дерево поиска с отсортированными массивами в узлах; для массивов внутренних узлов может быть задана минимальная заполненность

Может быть реализовано на основе AVL-дерева

- - - - - -

## Структуры данных: T-Tree (2)

Операции

* Поиск — очевидно
* Вставка:
  * в начале ищем узел, в который вставляем
  * если место в узле есть, то вставляем в его массив
  * если места нет, то вытесняем один из крайних и вставляем его в соответствующее поддерево
  * если добавили новый узел, балансируем
* Удаление:
  * если в массиве меньше минимума, пополняем из одного из детей рекуррентно
  * если в ком-то из детей не осталось, удаляем и балансируем
* Балансировка:
  * Как AVL, но если во внутреннем узле недобор, в него переносятся элементы из ребёнка

- - - - - -

## Структуры данных: T-Tree (3)

**Литература**

* Lehman T. J., Carey M. J. [A Study of Index Structures for Main Memory Database Management Systems](http://vldb.org/conf/1986/P294.PDF) // Proceedings of the 12th International Conference on Very Large Data Bases. – 1986. – С. 294-303.

По результату теста в полтора-два раза лучше B-дерева

@pause@

... на DEC VAX-11/750 с единицами КиБ кэша и единицами МиБ ОЗУ =)

Сейчас применение T-деревьев спорно:

* https://en.wikipedia.org/wiki/T-tree#Performance_and_Storage
* https://stackoverflow.com/a/40152956

= = = = = =

# Реализация: протоколы поддержки когерентности

- - - - - -

* Имеет смысл рассматривать вместе с протоколами консенсуса

= = = = = =

# Реализация: фреймворки и библиотеки

- - - - - -

## Фреймворки: Java Soft- и WeakReference

Это не реализация кеширование, но применение вытеснения при сборке мусора

@pause@

Здесь интереснее уже сами алгоритмы сборки мусора

@pause@

Аналогичная функциональность есть у многих других платформ

- - - - - -

## Средства [мемоизации](https://en.wikipedia.org/wiki/Memoization)


Фреймворки: Python `functools.lru_cache`

* Программирование в стиле «выльем воду из чайника и сведём задачу к предыдущей»: тест на простоту, числа Фибоначчи, факториалы и т.д.
* [Часть стандартной библиотеки](https://docs.python.org/3/library/functools.html#functools.lru_cache)
* Умеет выдавать статистику при помощи `cache_info()`

Функциональные и логические языки, например, Haskell

* `fibs = 1 : 1 : zipWith (+) fibs (tail fibs)`

- - - - - -

## Отдельные библиотеки: Python Cacheout

* https://pypi.org/project/cacheout/
* https://cacheout.readthedocs.io/
* тоже [может быть использован для мемоизации](https://cacheout.readthedocs.io/en/latest/cache.html#cacheout.cache.Cache.memoize)

- - - - - -

## Распределённые хранилища Key-Value

* [Apache Ignite](https://ignite.apache.org/)
* [Aerospike](https://www.aerospike.com/)

Имеет смысл рассматривать с NoSQL

= = = = = =

# Средства моделирования

- - - - - -

## Инструмент Mimircache

[Разработан](http://mimircache.info/) нашими коллегами из [университета Emory](http://emory.edu/)

Руководитель — [Ymir Vigfusson](http://ymsir.com/)

Инструмен на основе данных о порядке обращения к памяти, кэше и стратегии вытеснения умеет анализировать и выдавать, например:

* Hit Ratio в зависимости от размера кэша
* [Всякие более мудрёные вещи](https://pymimircache.readthedocs.io/en/develop/User/Tutorial/heatmap_plotting.html)

= = = = = =

# Вопросы и упражнения

## Вопросы

## Упражнения

* Самостоятельно познакомьтесь с описанием стратегии вытеснения для кэшей ARC