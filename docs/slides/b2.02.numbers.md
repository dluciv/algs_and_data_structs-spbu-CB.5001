<!-- -*- coding: utf-8 -*- -->
<span id="slides-title" hidden>Числа: точность, неотрицательные системы счисления, дополнительный код</span>

# Погрешность представления

- - - - - -

## Предмет


-   Целых, рациональных, а *тем более* вещественных чисел бесконечное
    количество.
-   Машинное представление обычно конечно и адекватно решаемой задаче
-   Представление с произвольной точностью и/или рациональное бывает, но
    аппаратно не поддерживается, да и программно условно

- - - - - -

## Абсолютная

***Абсолютная погрешность*** — отклонение числа, оптимально представленного
машиной $\in I^{(m)}$, от его действительного значения $\in I$.

@pause@

Для $I^{(m)}$ абсолютная погрешность не превышает 0,5, когда исходное
число лежит в множестве $I$, для представления элементов которого
предназначены машинные целые из множества $I^{(m)}$.

@pause@

Для наилучшего представления —

$$x^{(m)} \in I^{(m)}, x \in I: x^{(m)} = \arg\min_{{I^{(m)}}} \Delta^{(m)}(x)$$

Справедливо: $\Delta^{(m)}(I^{(m)})=\max_I \Delta^{(m)}(x)$

Постоянная абсолютная погрешность и у представления с фиксированной
запятой.

- - - - - -

## Относительная (I)

***Относительная погрешность*** — абсолютная погрешность, деленная на
абсолютную величину конкретного представляемого числа:

$$\delta^{(m)}(x) = \frac{\Delta^{(m)}(x)}{|x|}$$

@pause@

В общем же случае,

$$\delta^{(m)}(I^{(m)}) = \max_{x\in I} \frac{\Delta^{(m)} (x) } {|x|}$$

С постоянной относительной погрешностью стремятся (но не достигают)
представлять значения машинные числа с плавающей запятой.

@pause@

При представлении с постоянной погрешностью больших чисел, относительная
погрешность будет падать.

- - - - - -

## Относительная (II)

Для многих вычислений (особенно физических) важна именно относительная
погрешность:

Например, у «результата с тремя значащими цифрами», относительная
погрешность всегда $1\over 2000$.

@pause@

Биологическая *рецепторная функция* $f(x) = \ln(x)$.

$$f'(x) = \ln'{x} = 1/x$$

@pause@

При $\Delta \rightarrow 0$ справедливо
$\ln(x+\Delta) - \ln(x) = \mathcal{O}(\frac{\Delta}{x})$.

Если рецептор различает $f_1 = f(x)$ и
$f_2 = f(x)+\Delta_f = f(x+\Delta_x)$, то при
$\Delta_f = \mathsf{const}$, $\Delta_x = \mathcal{O}(x)$.

- - - - - -

## Диапазон

**Диапазон** — разность между наименьшим и наибольшим представляемыми
числами.

@pause@

### Фиксированная запятая

Важны не значения, как таковые, а скорее их количество.

@pause@

### Плавающая запятая

Информативны границы диапазона, даже для чисел одного знака.

$\min_{x \in I_f}|x|$ — максимальная точность для малых чисел (но не
относительная погрешность, т.к. в самом маленьком числе м.б. единица в
конце мантиссы, о длине которой мы наперед не знаем, см. ниже).

$\max_{x \in I_f}|x|$ — диапазон в его исходном смысле.

= = = = = =

# Неотрицательные позиционные системы

- - - - - -

## Основная информация

В самом общем виде неотрицательная позиционная система обладает
переменными основаниями $B_i: i\in\mathbb{N}, B_0=1$.

Число записывается
при помощи *цифр* $c_i: i \in [ 1, N ], c_i \in \left[ 0, B_i \right)$.

Значение же числа, записанного $N$ цифрами (Слово *цифра* арабское, по происхождению такое же, как слово
*шифр*) вычисляется по формуле:

$$v = \sum_{k=1}^N c_k \prod&#95;{i=0}^{k-1} B_i$$

@pause@

На практике, обычно, используется постоянное основание системы счисления
$B$, совпадающее с $B\_1$, так что: $$v = \sum_{k=1}^N c_k B_1^{k-1}$$

- - - - - -

## Корректность

### Однозначность (I)

-   Сначала покажем, что
    $1\times B^N > \sum_{k=1}^N (B-1)\times B^{k-1}$.

    @pause@

-   Для геометрической прогрессии
    $$S\_n = \sum\_{i=1}^n  b\_i = \frac{b\_1 - b\_{n+1}}{1-q}=b\_1\frac{q^n-1}{q-1},$$

    соответственно, $\sum_{k=1}^N B^{k-1} = 1\times \frac{B^N-1}{B-1},$

    А $\sum_{k=1}^N (B-1)\times B^{k-1} = (B-1)\frac{B^N-1}{B-1} = B^N-1.$

-   Таким образом, $N$ максимальными цифрами можно записать число, на 1
    меньшее, чем единицей и $N$ нулями.

- - - - - -

### Однозначность (II)

-   Пусть две записи числа отличаются, отличия проявляются вплоть до
    $k$-й цифры. Отличия в $k$-й цифре должны компенсироваться младшими.

    $$x = B^{N-1}c\_N + \ldots + B^{k-1}c\_k + \sum\_{i=1}^{k-1}B^{i-1}c\_i$$

    и

    $$x = B^{N-1}c\_N + \ldots + B^{k-1}c'\_k + \sum\_{i=1}^{k-1}B^{i-1}c'\_i$$

-   Но это невозможно, т.к.
    $$\forall c'\_i \in \left[0, B\right) \; B^{k-1} \times 1 > \sum\_{i=1}^{k-1}B^{i-1}c'\_i$$

- - - - - -

## Основание

Выбор основания системы счисления — задача важная сама по себе.
Например, двоичную арифметику при финансовых расчётах не используют,
т.к. $\frac{1}{10}$ в двоичной системе — бесконечная периодическая
дробь, а по сему точного конечного представления не имеет.

- - - - - -

## Перевод в неотрицательную позиционную систему

Осуществляется по простому алгоритму (использован язык Scheme, диалект
[LISP](http://www.lisperati.com/landoflisp/panel01.html)):

```
(define (val->posn value base)
  (if (= value 0)
      '() #| для нуля цифр не нужно |#
      (let ((digit (modulo value base)))
        (append
         (val->posn (/ (- value digit) base) base)
         (list digit)
         )
        )
      )
  )
```

= = = = = =

# Хранение чисел со знаком

* Прямой код
* Обратный код
* Дополнительный код

- - - - - -

## Прямой и обратный коды

Для $N$ разрядов:

* Выделенный знаковый бит
* $N-1$ битов мантиссы
  * У прямого кода они хранят модуль числа
  * У обратного — модуль неотрицательных или инвертированный модуль *неположительных*

@pause@

Недостатки:

* Два значения ±0
* Необходимость принятия решений при суммировании

- - - - - -

## Дополнительный код

Применим только к числам фиксированного размера.

Беззнаковое число $X^{(m)} \in [0,P), P=B^N$. Машина хранит только $N$
цифр.

$$ [x]_P = [x+nP]_P = \\{ x + Pk | k \in\mathbb{Z} \\} $$


$$[-1]_P = [P-1]_P, [-2]_P = [P-2]_P, \ldots$$ — мы сами вольны
рассматривать числа, как положительные, или как отрицательные.

@pause@

- Для представления отрицательных чисел берется число $s\in(0,P-1)$ и
    дальше принимается $[-s]_P = [P-s]_P$.
-  Обычно для четных $P$ берут $s=P/2$. Например, для $P=256$ —
   $s=128$.

@pause@

-  Беззнаковый байт — $[0,256)$, а знаковый —
   $[-128,0)\cup[0,128) = [-128,128)$.
-  Если машина работает с двоичными числами, то установленный старший
   бит соответствует строго отрицательному числу.

- - - - - -

## Вычитание в дополнительном коде

$$-[y] = [-y] = [P-y] = [(P-1-y) + 1]$$ — т.е. для отрицания инвертируем биты и прибавляем 1

@pause@

$$[x] - [y] = [x] + [-y]$$

- - - - - -

## Ещё немного про обратный код

* В прошлом — не такая и экзотика: использовался в таких знаменитых ЭВМ, как CDC 6600, the PDP-1
* Фактически — дополнение до $2^N - 1$ (а не до $2^N$)

@pause@

* И (внезапно!) сложение таких чисел также можно выполнять невзирая на знак!

= = = = = =

# Длинная арифметика

- - - - - -

## Сложение

На низком уровне использует флаг переноса

Пример: сложение 64-битных чисел на 32-битной ЭВМ

```
add eax, ebx
adc edx, ecx
```

Результат:

`edx:eax` $\gets$ ` edx:eax + acx:ebx`

- - - - - -

## Умножение

Андрей Николаевич Колмогоров: Гипотеза $n^2$ — *метод умножения «в столбик» известен не менее четырёх тысячелетий, и если бы был более быстрый метод умножения, то он, вероятно, уже был бы найден*

- - - - - -

## Умножение: алгорифм Карацубы

Анатолий алексеевич Карацуба, [1960](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9A%D0%B0%D1%80%D0%B0%D1%86%D1%83%D0%B1%D1%8B):

Пусть есть два $n$-значных числа $A=ax+b$ и $B=cx+d$, где n — чётное и $x=B^{n/2}$.

Тогда

$$AB = (ax+b)(cx+d)=acx^2+(ad+bc)x+bd.$$

@pause@

Вычислительная сложность:

$$T(n) = 3 T\left(\frac{n}{2}\right)+\mathcal{O}(n) = \mathcal{O}(n^{\log_2 3})$$

- - - - - -

## Умножение: более новые алгориѳмы

* [Арнольд Шёнхаге, Фолькер Штрассен](https://en.wikipedia.org/wiki/Sch%C3%B6nhage%E2%80%93Strassen_algorithm), 1971, $\mathcal{O}(n \cdot \log n \cdot \log \log n)$
  * Предположили, что можно за $\mathcal{O}(n \cdot \log n)$
  * Реализации быстрее Карацубы на числах $\approx 2^{2^{15}}\ldots 2^{2^{17}}$
* [Мартин Фюрер](https://en.wikipedia.org/wiki/F%C3%BCrer%27s_algorithm), 2007, $\mathcal{O}(n \log n \cdot 2^{O(\log^* n)})$
  * Быстрее предыдущего при умножении $10^{10^{4796}}$-знаковых чисел =)

@pause@

Алгориѳм Карацубы остаётся самым популярным, хотя современная криптография заставляет задуматься и о применении Шёнхаге-Штрассена

= = = = = =

# Упражнения и вопросы

- - - - - -

## Упражнения

* Придумать алгоритм преобразования периодической дроби в
простую. Можно запрограммировать.
* Придумать алгоритм преобразования простой дроби в
периодическую. Можно запрограммировать.
* Убедитесь, что вычитание в обратном коде, как и в дополнительном, корректно реализуется через сложение.
* Реализуйте арифметический целочисленный тип с использованием обратного кода.
* Реализуйте алгоритм Карацубы

## Вопросы

* Что такое абсолютная погрешность?
* Что такое относительная погрешность?
* Что такое диапазон представления?
* Почему для физических и инженерных задач большее значение имеет относительная погрешность?
* Что такое обратный код?
* Что такое дополнительный код?
* Как складываются числа в длинной арифметике
* Опишите алгоритм Карацубы
