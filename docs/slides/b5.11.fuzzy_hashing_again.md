<span id="slides-title" hidden>И снова нечёткое хэширование</span>

# О чём пойдёт речь

* Рандомизированные нечёткие хэш-функции
* Сравнение по значению нечётких хэш-функций
* Поиск похожих аргументов по значению нечётких хэш-функций

= = = = = =

# Рандомизированные нечёткие хэш-функциии

- - - - - -

## Вспомним «плохие» хэш-функции

II семестр, [хэш-функции и хэш-таблицы](https://dluciv.github.io/algs_and_data_structs-spbu-CB.5001/slides.html?md=08.hashtables#/2/1/1)

@pause@

«Плохие» функции не вызывают «лавинный» эффект, т.е. незначительное изменение аргумента не вызывает значительного изменения значения

- - - - - -

## Фильтр Блума

Проверяет, может ли элемент входить во множество. Допускает ложноположительные ответы.

* Множество представляется, как набор битов $\\{0, 1\\}^m$
* $h_1, \ldots, h_k: A \rightarrow I = \\{0, 1\\}^m$ — универсальные хэш-функции
* При добавлении элемента $x$ во множество выполняется побитовое *или*

$$S' = S \vee {\displaystyle \operatorname{\vee}_{i=1}^k}  h_i(x)$$

[Вероятность ложноположительного срабатывания](https://en.wikipedia.org/wiki/Bloom_filter#Probability_of_false_positives)

$$P = \left( 1-e^{-kn/m} \right)^k$$

Оптимальное $m$

$$k = \frac{m}{n} \ln 2$$

**Литература**

* B. H. Bloom. [Space/time trade-offs in hash coding with allowable errors](https://web.archive.org/web/20170809034527/http://www.cs.princeton.edu/courses/archive/spring05/cos598E/bib/p422-bloom.pdf). Commun. ACM 13, 7 (July 1970), 422–426.

- - - - - -

## Схожесть и различия

Мера схожести Жаккара

$$J(A'\subset A, A'' \subset A) = \frac{|A' \cap A''|}{|A' \cup A''|}$$

Расстояние Хэммминга

$$\operatorname{dist}_H (A', A'') = | A' \triangle A'' |$$

**Литература**

* Jaccard, Paul (1901), [Étude comparative de la distribution florale dans une portion des Alpes et des Jura](https://upload.wikimedia.org/wikipedia/commons/e/e0/%C3%89tude_comparative_de_la_distribution_florale_dans_une_portion_des_Alpes_et_du_Jura.pdf), Bulletin de la Société vaudoise des sciences naturelles, 37: 547–579 (фр.)
* R. W. Hamming, [Error detecting and error correcting codes](https://calhoun.nps.edu/bitstream/handle/10945/46756/Hamming_1982.pdf) in The Bell System Technical Journal, vol. 29, no. 2, pp. 147-160, April 1950

- - - - - -

## MinHash: хэш-функция

1. Пусть $\\{h \in H: A \rightarrow I\\}$ — универсальные хэш-функция
2. Выбираетм $h \in H$
3. $h_{min}(A' \subset A) = \min_{a \in A'} h(a)$

**Литература**

* A. Z. Broder. [On the resemblance and containment of documents](https://web.archive.org/web/20150131043133/http://gatekeeper.dec.com/ftp/pub/dec/SRC/publications/broder/positano-final-wpnums.pdf) // Proceedings. Compression and Complexity of SEQUENCES 1997, Salerno, Italy, 1997, pp. 21-29

- - - - - -

## MinHash: мера Жаккара

На шаге (2) можем выбрать не одну ($h \in H$), а несколько ($H' \subset H,\, |H'|=k$) хэш-функций. Тогда можно доказать:

$$\operatorname{P}(\forall h \in H' \subset H\, h_{min}(A') = h_{min}(A'')) \overset{k\rightarrow|H|}{\rightarrow} J(A', A'')$$

* На практике можно взять среднее значение из $h_{min\, 1},\ldots, h_{min\, k}$
* Если при вычислении $J$ нас устраивает ошибка $\varepsilon$, достаточно взять $k = |H'| = \left\lceil\frac{1}{\varepsilon^2}\right\rceil$


- - - - - -

## SimHash: хэш-функция

Так же, как MinHash, но:

* Не минимум, а сразу побитовое среднее
* Среднее округляется к ближайшему целому (0 или 1)

**Литература**

Charikar M. S. [Similarity estimation techniques from rounding algorithms](https://web.archive.org/web/20200709090229/https://www.cs.princeton.edu/courses/archive/spr04/cos598B/bib/CharikarEstim.pdf) // Proceedings of the thiry-fourth annual ACM symposium on Theory of computing. – 2002. – С. 380-388.

- - - - - -

## SimHash: метрика Хэмминга

Между двумя аргументами — очевидным образом это оно.

При усреднении можно, например, [пользоваться разными весами для разных частей текста](https://web.archive.org/web/20200504085128/http://benwhitmore.altervista.org/simhash-and-solving-the-hamming-distance-problem-explained/)

- - - - - -

## Какая была идея?

* Миллион мартышек за миллион лет напечатают Войну и мир или Гамлета. Если не будут умничать, а будут вести себя статистически правильно.

@pause@

* Много бессмысленных хэш-функций, смогут «нащупать» особенности данных
  * Особенности будут бессмысленными, но значимыми, т.е. будут эти данные идентифицировать
  * И у нас уже был сходный пример с рандомизированными базисами

- - - - - -

## Пример ковейера обработки данных

Для длинных документов

* Загрузка документов
* Конвертация в текстовый формат
* Очистка, лемматизация (нахождение части речи и перевод в нейтральную форму) или стемминг (выделение основ слов) текста
* Выделение N-грамм (для текста «Однажды в студёную зимнюю пору» триграммы: «Однажды в студёную», «в студёную зимнюю», «студёную зимнюю пору»)
* Вычисление MinHash или SimHash для документов

@pause@

* А дальше-то что?.. =)

= = = = = =

# Locality-Sensitive Hashing

- - - - - -

## Чувствительность к расстоянию

Система LSH имеет свойства $R, cR, p_1, p_2$, такие, что

* $\mathit{dist}(x,y) \leq R \Rightarrow \forall h \in H\, \operatorname{P}(h(x) = h(y)) \geq p_1$
* $\mathit{dist}(x,y) \geq cR \Rightarrow \forall h \in H\, \operatorname{P}(h(x) = h(y)) \leq p_2$

**Литература**

* Indyk P., Motwani R. [Approximate nearest neighbors: towards removing the curse of dimensionality](https://web.archive.org/web/20200926050407/http://www.theoryofcomputing.org/articles/v008a014/v008a014.pdf) // Proceedings of the thirtieth annual ACM symposium on Theory of computing. – 1998. – С. 604-613.

- - - - - -

## Варианты расстояния для сравнения

В качестве $dist(x, y)$ вычисляется $|| x - y ||$

1. Метрика Хэмминга — сумма по отличающимся битам или случайный взятые биты
2. Случайные проекции — берутся не координаты, а проекции случайные векторы, распределённые по закону Гаусса
   * Вектора $x$ и $y$ можно нормировать, тогда мы будем сравнивать «соотвествие идей», а не их «выраженность»
3. Евклидово расстояние и различные расстояния Минковского.

[Подробно тут](https://web.archive.org/web/20201028122213/https://randorithms.com/2019/09/19/Visual-LSH.html)

- - - - - -

## Поиск похожих по метрике Хэмминга

Пусть у нас $10^7$ документов. Для поиска похожих придётся сравнить $5\cdot 10^{13}$... Очевидно, лучше сравнивать хэши, а не документы.

Пусть у нас есть 64-битный SimHash $10^7 < 2^{24}$ по документам. Можно построить несколько отсортированных индексов по подмножествам этих битов и по документу искать, похожие в этих индексах.

И [для SimHash](https://web.archive.org/web/20200504085128/http://benwhitmore.altervista.org/simhash-and-solving-the-hamming-distance-problem-explained/), и [для MinHash](https://web.archive.org/web/20201218151632/https://habr.com/ru/post/250673/)

@pause@

Пример реального кода:

1. [Берутся ключи](https://github.com/1e0ng/simhash/blob/8987a06d7afeee0e00b520bbd53a415cf8d85a7a/simhash/__init__.py#L248)
2. [Для всех ключей добавляется в соотвесттвующие бакеты](https://github.com/1e0ng/simhash/blob/8987a06d7afeee0e00b520bbd53a415cf8d85a7a/simhash/__init__.py#L227)

= = = = = =

## Вопросы

* Что такое фильтр Блума?
* Что такое мера Жаккара и метрика Хэмминга?
* Опишите принципы построения MinHash и SimHash
* Опишите принцип Locality Sensitive Hashing
* Опишите пример применения LSH для поиска

## Упражнения

* На любом языке програмирования реализуйте систему индексирования и поиска в реальной коллекции документов, использующую LSH и расстояние Хэммиинга